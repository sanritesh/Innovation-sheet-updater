image: python:3.9

definitions:
  services:
    docker:
      memory: 2048

pipelines:
  default:
    - step:
        name: Download and Process Booking Data
        services:
          - docker
        script:
          # Install Chrome and dependencies
          - apt-get update && apt-get install -y wget gnupg2 curl
          - wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add -
          - echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list
          - apt-get update && apt-get install -y google-chrome-stable
          
          # Install Python dependencies
          - pip install -r requirements.txt
          
          # Create necessary directories
          - mkdir -p /tmp/BookingData_folder
          - mkdir -p logs
          
          # Run the Expresso booking data download script
          - echo "Starting Expresso data download..."
          - python main.py
          
          # Wait for 10 seconds
          - echo "Waiting for 10 seconds before processing data..."
          - sleep 10
          
          # Verify downloaded file exists
          - |
            if [ ! -f "/tmp/BookingData_folder/BookingData.xlsx" ]; then
              echo "❌ Downloaded file not found"
              exit 1
            else
              echo "✅ Found downloaded file: /tmp/BookingData_folder/BookingData.xlsx"
              ls -la /tmp/BookingData_folder/BookingData.xlsx
            fi
          
          # Decode base64 service account JSON and save to file
          - echo "Decoding and saving service account JSON..."
          - echo $SERVICE_ACCOUNT_JSON | base64 -d > /tmp/service-account.json
          
          # Verify service account file
          - echo "Verifying service account file..."
          - |
            if [ ! -f "/tmp/service-account.json" ]; then
              echo "❌ Service account file not created"
              exit 1
            else
              echo "✅ Service account file created successfully"
              ls -la /tmp/service-account.json
            fi
          
          # Check if the JSON is valid
          - |
            if ! python3 -c "import json; f = open('/tmp/service-account.json'); json.load(f)"; then
              echo "❌ Invalid JSON in service account file"
              exit 1
            else
              echo "✅ Service account JSON is valid"
            fi
          
          # Run the data processing script with environment variables
          - export DOWNLOAD_DIR=/tmp/BookingData_folder
          - echo "Starting data processing..."
          - |
            if python dailyInnov_V2.py /tmp/BookingData_folder/BookingData.xlsx; then
              echo "✅ Data processing completed successfully"
              echo "Contents of logs directory:"
              ls -la logs/
            else
              echo "❌ Data processing failed"
              exit 1
            fi
          
        artifacts:
          - /tmp/BookingData_folder/**
          - logs/**
          - error_*.png
          - /tmp/service-account.json
        environment:
          EXPRESSO_USERNAME: ${EXPRESSO_USERNAME}
          EXPRESSO_PASSWORD: ${EXPRESSO_PASSWORD}
          GOOGLE_SHEET_URL: ${GOOGLE_SHEET_URL}
          SERVICE_ACCOUNT_JSON: ${SERVICE_ACCOUNT_JSON}
        after-script:
          # Debug file locations
          - |
            echo "=== Debug Information ==="
            echo "Current directory: $(pwd)"
            echo "Files in /tmp/BookingData_folder:"
            ls -la /tmp/BookingData_folder/ || true
            echo "Files in logs:"
            ls -la logs/ || true
            echo "=== End Debug Information ==="
          # Trigger Google Apps Script webhook with timeout and retry
          - |
            if [ "$BITBUCKET_EXIT_CODE" = "0" ]; then
              echo "Pipeline successful, triggering Google Apps Script..."
              echo "Webhook URL: ${GOOGLE_APPS_SCRIPT_URL}"
              echo "Token being used: TIL_ADTECH_QUALITY_2024"
              
              max_retries=3
              retry_count=0
              while [ $retry_count -lt $max_retries ]; do
                echo "Attempt $((retry_count + 1)) of $max_retries"
                echo "Sending POST request to webhook..."
                
                # Store the full URL for debugging
                webhook_url="${GOOGLE_APPS_SCRIPT_URL}?token=TIL_ADTECH_QUALITY_2024"
                echo "Full webhook URL: $webhook_url"
                
                # Make the request with verbose output
                response=$(curl -v -s -X POST --max-time 300 "$webhook_url" 2>&1)
                curl_exit_code=$?
                
                echo "Curl exit code: $curl_exit_code"
                echo "Full response:"
                echo "$response"
                
                if [ $curl_exit_code -eq 0 ]; then
                  echo "✅ Google Apps Script triggered successfully"
                  # Check if the response indicates success
                  if echo "$response" | grep -q '"status":"success"'; then
                    echo "✅ Apps Script execution successful"
                    break
                  else
                    echo "❌ Apps Script returned error: $response"
                    retry_count=$((retry_count + 1))
                    if [ $retry_count -lt $max_retries ]; then
                      echo "Retrying in 30 seconds..."
                      sleep 30
                    fi
                  fi
                else
                  retry_count=$((retry_count + 1))
                  echo "❌ Attempt $retry_count failed with curl exit code $curl_exit_code"
                  echo "Error details: $response"
                  if [ $retry_count -lt $max_retries ]; then
                    echo "Retrying in 30 seconds..."
                    sleep 30
                  fi
                fi
              done
              
              if [ $retry_count -eq $max_retries ]; then
                echo "❌ Failed to trigger Google Apps Script after $max_retries attempts"
                exit 1
              fi
            else
              echo "Pipeline failed, not triggering Google Apps Script"
              exit 1
            fi

  schedules:
    - cron: '0 6 * * *'  # 11:30 AM IST (6:00 UTC) All 7 Days
      branches:
        include:
          - main  # or your default branch name
      name: Morning Data Update
      definition: default

    - cron: '0 11 * * *'  # 4:30 PM IST (11:00 UTC) All 7 Days
      branches:
        include:
          - main  # or your default branch name
      name: Evening Data Update
      definition: default 