image: python:3.9

definitions:
  services:
    docker:
      memory: 2048

pipelines:
  default:
    - step:
        name: Download and Process Booking Data
        services:
          - docker
        script:
          # Install Chrome and dependencies
          - apt-get update
          - apt-get install -y wget gnupg2 curl tree
          - wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add -
          - echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list
          - apt-get update
          - apt-get install -y google-chrome-stable xvfb
          - apt-get install -y libgconf-2-4 libnss3 libxss1 libasound2
          
          # Install Python dependencies with specific versions
          - pip install --no-cache-dir -r requirements.txt
          
          # Set up Xvfb for headless Chrome
          - Xvfb :99 -screen 0 1920x1080x24 > /dev/null 2>&1 &
          - export DISPLAY=:99.0
          
          # Directory setup with proper permissions
          - |
            echo "=== Setting up directories with proper permissions ==="
            rm -rf /tmp/BookingData_folder
            mkdir -p /tmp/BookingData_folder
            chmod 777 /tmp/BookingData_folder
            mkdir -p logs
            chmod 777 logs
            
            # Verify directory setup
            echo "Directory permissions:"
            ls -la /tmp/BookingData_folder
            ls -la logs
            
            # Set environment variable for Chrome
            export CHROME_BIN=/usr/bin/google-chrome
            
            # Test Chrome installation
            echo "Chrome version:"
            google-chrome --version
            
            # Run main.py with detailed output
            echo "=== Running main.py ==="
            python -u main.py
            
            # Wait and verify downloaded file with retries
            echo "=== Waiting for file download and verification ==="
            max_wait_attempts=30  # Maximum number of attempts (5 minutes total with 10s intervals)
            attempt=1
            file_ready=0
            
            while [ $attempt -le $max_wait_attempts ]; do
              echo "Attempt $attempt of $max_wait_attempts: Checking for BookingData.xlsx..."
              
              if [ -f "/tmp/BookingData_folder/BookingData.xlsx" ]; then
                # Check if file size is stable (not still being written)
                size1=$(stat -f %z "/tmp/BookingData_folder/BookingData.xlsx")
                sleep 5  # Wait 5 seconds
                size2=$(stat -f %z "/tmp/BookingData_folder/BookingData.xlsx")
                
                if [ "$size1" = "$size2" ]; then
                  echo "✅ File found and size is stable: $size2 bytes"
                  file_ready=1
                  break
                else
                  echo "File size changing ($size1 -> $size2), still being written..."
                fi
              else
                echo "File not found yet..."
              fi
              
              echo "Waiting 10 seconds before next check..."
              sleep 10
              attempt=$((attempt + 1))
            done
            
            if [ $file_ready -eq 0 ]; then
              echo "❌ ERROR: BookingData.xlsx not found or not stable after maximum wait time"
              echo "Directory contents:"
              ls -la /tmp/BookingData_folder/
              exit 1
            fi
            
            echo "=== File verification passed, proceeding with processing ==="
            
            # Process data with dailyInnov_V2.py
            echo "=== Processing data ==="
            python -u dailyInnov_V2.py /tmp/BookingData_folder/BookingData.xlsx
            
            # Verify processing results
            echo "=== Checking processing results ==="
            ls -la logs/
            
            # Set up service account
            echo $SERVICE_ACCOUNT_JSON | base64 -d > /tmp/service-account.json
            chmod 600 /tmp/service-account.json
            
        artifacts:
          - /tmp/BookingData_folder/**
          - logs/**
          - error_*.png
          - /tmp/service-account.json
          - download.log
          - processing.log
        environment:
          EXPRESSO_USERNAME: ${EXPRESSO_USERNAME}
          EXPRESSO_PASSWORD: ${EXPRESSO_PASSWORD}
          GOOGLE_SHEET_URL: ${GOOGLE_SHEET_URL}
          SERVICE_ACCOUNT_JSON: ${SERVICE_ACCOUNT_JSON}
          DISPLAY: :99.0
        after-script:
          - |
            echo "=== Final State Verification ==="
            echo "Current directory: $(pwd)"
            echo "Complete directory tree:"
            tree /tmp/BookingData_folder/
            tree logs/
            
            if [ -f "/tmp/BookingData_folder/BookingData.xlsx" ]; then
              echo "✅ BookingData.xlsx exists in final state"
              echo "Final file details:"
              ls -la /tmp/BookingData_folder/BookingData.xlsx
              echo "File size: $(stat -f %z /tmp/BookingData_folder/BookingData.xlsx) bytes"
            else
              echo "❌ BookingData.xlsx missing in final state"
            fi
            
            echo "Log files:"
            echo "=== Download Log ==="
            cat download.log || echo "Download log not found"
            echo "=== Processing Log ==="
            cat processing.log || echo "Processing log not found"
            echo "=== Error Log ==="
            cat logs/error.log || echo "Error log not found"

          # Webhook trigger with verification
          - |
            if [ "$BITBUCKET_EXIT_CODE" = "0" ]; then
              echo "Pipeline successful, performing final verification..."
              
              if [ ! -f "/tmp/BookingData_folder/BookingData.xlsx" ]; then
                echo "❌ ERROR: BookingData.xlsx not found before webhook trigger"
                exit 1
              fi
              
              if [ ! -s "/tmp/BookingData_folder/BookingData.xlsx" ]; then
                echo "❌ ERROR: BookingData.xlsx is empty"
                echo "File details:"
                ls -la /tmp/BookingData_folder/BookingData.xlsx
                exit 1
              fi
              
              echo "✅ Data verification passed, triggering Google Apps Script..."
              echo "Webhook URL: ${GOOGLE_APPS_SCRIPT_URL}"
              
              max_retries=3
              retry_count=0
              while [ $retry_count -lt $max_retries ]; do
                echo "Attempt $((retry_count + 1)) of $max_retries"
                response=$(curl -v -s -X POST --max-time 300 "${GOOGLE_APPS_SCRIPT_URL}?token=TIL_ADTECH_QUALITY_2024" 2>&1)
                curl_exit_code=$?
                
                echo "Curl exit code: $curl_exit_code"
                echo "Response: $response"
                
                if [ $curl_exit_code -eq 0 ]; then
                  if echo "$response" | grep -q '"status":"success"'; then
                    echo "✅ Apps Script execution successful"
                    break
                  else
                    echo "❌ Apps Script returned error: $response"
                  fi
                fi
                
                retry_count=$((retry_count + 1))
                if [ $retry_count -lt $max_retries ]; then
                  echo "Retrying in 30 seconds..."
                  sleep 30
                fi
              done
              
              if [ $retry_count -eq $max_retries ]; then
                echo "❌ Failed to trigger Google Apps Script after $max_retries attempts"
                exit 1
              fi
            else
              echo "Pipeline failed, not triggering Google Apps Script"
              exit 1
            fi

  schedules:
    - cron: '0 6 * * *'  # 11:30 AM IST (6:00 UTC) All 7 Days
      branches:
        include:
          - main
      name: Morning Data Update
      pipeline: default

    - cron: '0 11 * * *'  # 4:30 PM IST (11:00 UTC) All 7 Days
      branches:
        include:
          - main
      name: Evening Data Update
      pipeline: default 